---
layout: default
title: "EDA"
date: 2025-09-25
categories: [machine-learning]
---

# Automated EDA with Pandas Profiling

## **Library Overview**
- **Library Name**: `pandas-profiling`
- **Purpose**: Automates exploratory data analysis (EDA)
- **Benefits**:
  - Saves time by performing extensive analysis in one line
  - Provides comprehensive insights into data quality, distributions, correlations, and missing values
  - Generates interactive HTML reports with visualizations
  - Detects high cardinality, duplicates, and outliers

---

## **Installation**
```bash
pip install pandas-profiling
```

---

## **Basic Usage**
```python
from pandas_profiling import ProfileReport

# Create profile report
profile = ProfileReport(df)

# Export report to HTML
profile.to_file('output.html')
```

- **Workflow**:
  1. Import the library and pass a DataFrame to `ProfileReport()`
  2. Run `to_file()` to save a detailed HTML report
  3. Open the report in a browser to explore:
     - Overview of dataset
     - Variable types and statistics
     - Interactions between variables
     - Correlations
     - Missing values
     - Sample data previews

---

## **Key Benefits of Using Pandas Profiling**
- **Automated Analysis**: Generates all essential EDA insights in seconds
- **Time Efficient**: Eliminates the need for repetitive manual visualizations and calculations
- **Data Quality Insights**: Detects missing values, duplicates, high cardinality, and outliers
- **Feature Relationship Discovery**: Highlights correlations and interactions automatically
- **Interactive Visualizations**: Makes it easy to explore the dataset and extract insights quickly

---

## **Summary**
Using `pandas-profiling`, you can perform comprehensive exploratory data analysis with minimal code. It is an essential tool for quickly understanding dataset structure, quality, and patterns before moving on to data preprocessing or modeling.

---

# Initial Data Exploration & EDA Summary

When you first get a dataset, perform these steps to understand structure, quality, and patterns.

## **1. Basic Checks**

### Dataset size
```python
df.shape
```

### Random sample
```python
df.sample(5)
```

### Data types & memory usage
```python
df.info()
```

### Missing values
```python
df.isnull().sum()
```

### Statistical summary (numerical)
```python
df.describe()
```

### Duplicate rows
```python
df.duplicated().sum()
```

### Correlations (numerical)
```python
df.corr()
```

## **2. Univariate Analysis**

### Categorical variables
- **Count plot**
```python
sns.countplot(data=df, x='Pclass')
```
- **Pie chart**
```python
plt.pie(df['Sex'].value_counts(), labels=df['Sex'].value_counts().index, autopct='%1.1f%%')
```

### Numerical variables
- **Histogram**
```python
plt.hist(df['Age'].dropna(), bins=30)
```
- **Distribution plot**
```python
sns.distplot(df['Fare'].dropna())
```
- **Box plot**
```python
sns.boxplot(data=df, x='Age')
```

## **3. Multivariate Analysis**

### 3.1 Numerical vs Numerical
```python
sns.scatterplot(data=df, x='Age', y='Fare', hue='Survived')
sns.jointplot(data=df, x='Age', y='Fare', kind='scatter')
df[['Age','Fare']].corr()
```

### 3.2 Categorical vs Categorical
```python
pd.crosstab(df['Pclass'], df['Survived'])
sns.heatmap(pd.crosstab(df['Pclass'], df['Survived']), annot=True, fmt='d', cmap='YlGnBu')
sns.countplot(data=df, x='Pclass', hue='Survived')
```

### 3.3 Numerical vs Categorical
```python
sns.boxplot(data=df, x='Pclass', y='Fare')
sns.violinplot(data=df, x='Survived', y='Age')
df.groupby('Pclass')['Fare'].mean()
df.groupby(['Pclass','Sex'])['Survived'].mean()
```

## **4. Pivot Table + Cluster Map Approach**

This method helps visualize relationships across multiple categorical & numerical features.

### Step 1: Create a pivot table
```python
pivot = df.pivot_table(index='Pclass', columns='Sex', values='Survived', aggfunc='mean')
```

### Step 2: Create a cluster map from the pivot table
```python
sns.clustermap(pivot, annot=True, cmap='coolwarm')
```

- **Pivot table** organizes values (like survival rate) by categories.  
- **Cluster map** automatically groups similar rows/columns and provides a heatmap for easy pattern recognition.

## **5. Advanced Visualizations**
```python
sns.pairplot(df, hue='Survived')
sns.FacetGrid(df, col='Survived').map(plt.hist, 'Age')
```

## **6. Summary & Workflow**

1. Start with **basic dataset checks** (shape, sample, dtypes, missing values, duplicates, correlation).  
2. Perform **univariate analysis** for single-variable insights (frequency, distribution, outliers).  
3. Conduct **multivariate analysis**:
   - Numerical-Numerical → scatter, jointplot, pairplot  
   - Categorical-Categorical → crosstab, countplot, heatmap  
   - Numerical-Categorical → boxplot, violin, groupby  
4. Use **pivot table + cluster map** for advanced categorical & numerical interactions.  
5. Apply **FacetGrid / Pairplot / Clustermap** to visualize complex patterns.  
6. Insights guide preprocessing, feature selection, and modeling decisions.
